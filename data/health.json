[{"epfl-llm/meditron-70b": ["## Model Details", "### Model Sources", "## Uses", "### Direct Use", "### Downstream Use", "### Out-of-Scope Use", "## Truthfulness, Helpfulness, Risk, and Bias", "### Recommendations", "## Training Details", "### Training Data", "#### Data Preprocessing", "### Training Procedure ", "#### Training Hyperparameters", "#### Speeds, Sizes, Times", "## Evaluation", "### Testing Data & Metrics", "#### Testing Data", "#### Metrics", "### Results", "## Environmental Impact", "## Citation"]}, {"TheBloke/med42-70B-GGUF": ["## Description", "### About GGUF", "## Repositories available", "## Prompt template: Med42", "## Licensing", "## Compatibility", "## Explanation of quantisation methods", "## Provided files", "### Q6_K and Q8_0 files are split and require joining", "### q6_K ", "### q8_0", "## How to download GGUF files", "### In `text-generation-webui`", "### On the command line, including multiple files at once", "## Example `llama.cpp` command", "## How to run in `text-generation-webui`", "## How to run from Python code", "### How to load this model in Python code, using ctransformers", "#### First install the package", "#### Simple ctransformers example code", "## How to use with LangChain", "## Discord", "## Thanks, and how to contribute", "## Model Details", "## Intended Use", "## Hardware and Software", "## Evaluation Results", "### Key performance metrics:", "## Limitations & Safe Use", "## Accessing Med42 and Reporting Issues"]}, {"TheBloke/meditron-70B-GGUF": ["## Description", "### About GGUF", "## Repositories available", "## Prompt template: ChatML", "## Compatibility", "## Explanation of quantisation methods", "## Provided files", "### Q6_K and Q8_0 files are split and require joining", "### q6_K ", "### q8_0", "## How to download GGUF files", "### In `text-generation-webui`", "### On the command line, including multiple files at once", "## Example `llama.cpp` command", "## How to run in `text-generation-webui`", "## How to run from Python code", "### How to load this model in Python code, using llama-cpp-python", "#### First install the package", "#### Simple llama-cpp-python example code", "## How to use with LangChain", "## Discord", "## Thanks, and how to contribute", "## Model Details", "### Model Sources", "## Uses", "### Direct Use", "### Downstream Use", "### Out-of-Scope Use", "## Truthfulness, Helpfulness, Risk, and Bias", "### Recommendations", "## Training Details", "### Training Data", "#### Data Preprocessing", "### Training Procedure", "#### Training Hyperparameters", "#### Speeds, Sizes, Times", "## Evaluation", "### Testing Data & Metrics", "#### Testing Data", "#### Metrics", "### Results", "## Environmental Impact", "## Citation"]}, {"TheBloke/med42-70B-AWQ": ["## Description", "### About AWQ", "## Repositories available", "## Prompt template: Med42", "## Licensing", "## Provided files, and AWQ parameters", "## How to easily download and use this model in [text-generation-webui](https://github.com/oobabooga/text-generation-webui)", "## Multi-user inference server: vLLM", "## Multi-user inference server: Hugging Face Text Generation Inference (TGI)", "## Inference from Python code using AutoAWQ", "### Install the AutoAWQ package", "### AutoAWQ example code", "## Compatibility", "## Discord", "## Thanks, and how to contribute", "## Model Details", "## Intended Use", "## Hardware and Software", "## Evaluation Results", "### Key performance metrics:", "## Limitations & Safe Use", "## Accessing Med42 and Reporting Issues"]}, {"m42-health/med42-70b": ["## Model Details", "## Intended Use", "## Hardware and Software", "## Evaluation Results", "### Key performance metrics:", "## Limitations & Safe Use", "## Accessing Med42 and Reporting Issues", "## Citation"]}, {"mradermacher/Mr-Grammatology-clinical-problems-Mistral-7B-0.5-GGUF": ["## About", "## Usage", "## Provided Quants", "## FAQ / Model Request", "## Thanks"]}, {"TheBloke/meditron-70B-AWQ": ["## Description", "### About AWQ", "## Repositories available", "## Prompt template: ChatML", "## Provided files, and AWQ parameters", "## How to easily download and use this model in [text-generation-webui](https://github.com/oobabooga/text-generation-webui)", "## Multi-user inference server: vLLM", "## Multi-user inference server: Hugging Face Text Generation Inference (TGI)", "## Inference from Python code using Transformers", "### Install the necessary packages", "### Transformers example code (requires Transformers 4.35.0 and later)", "## Compatibility", "## Discord", "## Thanks, and how to contribute", "## Model Details", "### Model Sources", "## Uses", "### Direct Use", "### Downstream Use", "### Out-of-Scope Use", "## Truthfulness, Helpfulness, Risk, and Bias", "### Recommendations", "## Training Details", "### Training Data", "#### Data Preprocessing", "### Training Procedure ", "#### Training Hyperparameters", "#### Speeds, Sizes, Times", "## Evaluation", "### Testing Data & Metrics", "#### Testing Data", "#### Metrics", "### Results", "## Environmental Impact", "## Citation"]}, {"rhaymison/Mistral-portuguese-luana-7b-mental-health": ["### FULL MODEL : A100", "### HALF MODEL: L4", "### 8bit or 4bit : T4 or V100", "### Comments"]}, {"ml4pubmed/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext_pub_section": ["## usage in python", "## metadata", "### training_metrics"]}, {"noxinc/Mistral-portuguese-luana-7b-mental-health-Q5_K_M-GGUF-PTBR": ["## Use with llama.cpp"]}, {"noxinc/Mistral-portuguese-luana-7b-mental-health-Q8_0-GGUF-PTBR": ["## Use with llama.cpp"]}, {"TheBloke/meditron-70B-GPTQ": ["## Repositories available", "## Prompt template: ChatML", "## Known compatible clients / servers", "## Provided files, and GPTQ parameters", "## How to download, including from branches", "### In text-generation-webui", "### From the command line", "### With `git` (**not** recommended)", "## How to easily download and use this model in [text-generation-webui](https://github.com/oobabooga/text-generation-webui)", "## Serving this model from Text Generation Inference (TGI)", "## Python code example: inference from this GPTQ model", "### Install the necessary packages", "### Example Python code", "## Compatibility", "## Discord", "## Thanks, and how to contribute", "## Model Details", "### Model Sources", "## Uses", "### Direct Use", "### Downstream Use", "### Out-of-Scope Use", "## Truthfulness, Helpfulness, Risk, and Bias", "### Recommendations", "## Training Details", "### Training Data", "#### Data Preprocessing", "### Training Procedure ", "#### Training Hyperparameters", "#### Speeds, Sizes, Times", "## Evaluation", "### Testing Data & Metrics", "#### Testing Data", "#### Metrics", "### Results", "## Environmental Impact", "## Citation"]}, {"ml4pubmed/scibert-scivocab-uncased_pub_section": ["## usage in python", "## metadata", "### training_metrics", "### training_parameters"]}, {"Zakia/gpt2-drugscom_depression_reviews-hq-v1": ["## Model Details", "### Model Description", "## Uses", "### Direct Use", "### Out-of-Scope Use", "## Bias, Risks, and Limitations", "### Recommendations", "## How to Get Started with the Model", "## Training Details", "### Training Data", "### Training Procedure ", "#### Preprocessing", "#### Training Hyperparameters", "## Evaluation", "#### Metrics", "### Results", "### Evaluation Results", "## Technical Specifications", "### Model Architecture and Objective", "### Compute Infrastructure", "#### Hardware", "## Citation", "## More Information", "## Model Card Authors", "## Model Card Contact"]}, {"Chhabi/mt5-small-finetuned-Nepali-Health-50k-2": ["### Training Procedure", "## Use Case", "## Evaluation", "### BLEU score:"]}, {"dibsondivya/distilbert-phmtweets-sutd": ["## Usage", "### Model Evaluation Results"]}, {"dibsondivya/ernie-phmtweets-sutd": ["## Usage", "### Model Evaluation Results", "## References for ERNIE 2.0 Model"]}, {"emre570/google-vit-large-finetuned": []}, {"ml4pubmed/xtremedistil-l12-h384-uncased_pub_section": ["## usage in python", "## metadata", "### training_parameters"]}, {"Zakia/distilbert-drugscom_depression_reviews": ["## Model Details", "### Model Description", "## Uses", "### Direct Use", "### Out-of-Scope Use", "## Bias, Risks, and Limitations", "### Recommendations", "## How to Get Started with the Model", "## Training Details", "### Training Data", "### Training Procedure ", "#### Preprocessing", "#### Training Hyperparameters", "## Evaluation", "### Testing Data, Factors & Metrics", "#### Testing Data", "#### Preprocessing", "#### Metrics", "### Results", "## Technical Specifications", "### Model Architecture and Objective", "### Compute Infrastructure", "#### Hardware", "## Citation", "## Glossary", "## More Information", "## Model Card Authors", "## Model Card Contact"]}, {"NepaliAI/NFT-6.9k": ["## Model Details", "### Model Description", "### Intended Use", "### Training Data", "### Training Procedure", "## Use case: ", "## Evaluation", "### Metrics", "### Limitations", "## Ethical Considerations", "### Intended Use", "### Bias", "### Privacy", "## Future Directions", "## License"]}, {"Zakia/gpt2-drugscom_depression_reviews": ["## Model Details", "### Model Description", "## Uses", "### Direct Use", "### Out-of-Scope Use", "## Bias, Risks, and Limitations", "### Recommendations", "## How to Get Started with the Model", "## Training Details", "### Training Data", "### Training Procedure ", "#### Preprocessing", "#### Training Hyperparameters", "## Evaluation", "#### Metrics", "### Results", "## Technical Specifications", "### Model Architecture and Objective", "### Compute Infrastructure", "#### Hardware", "## Citation", "## More Information", "## Model Card Authors", "## Model Card Contact"]}, {"TheBloke/med42-70B-GPTQ": ["## Description", "## Repositories available", "## Prompt template: Med42", "## Licensing", "## Known compatible clients / servers", "## Provided files, and GPTQ parameters", "## How to download, including from branches", "### In text-generation-webui", "### From the command line", "### With `git` (**not** recommended)", "## How to easily download and use this model in [text-generation-webui](https://github.com/oobabooga/text-generation-webui)", "## Serving this model from Text Generation Inference (TGI)", "## How to use this GPTQ model from Python code", "### Install the necessary packages", "### You can then use the following code", "## Compatibility", "## Discord", "## Thanks, and how to contribute", "## Model Details", "## Intended Use", "## Hardware and Software", "## Evaluation Results", "### Key performance metrics:", "## Limitations & Safe Use", "## Accessing Med42 and Reporting Issues"]}, {"rasta/BART-FHIR-question": ["### Training hyperparameters", "### Training results", "## How to use", "### Framework versions"]}, {"moriire/phi-2-healthcare": ["## Model description", "## Intended uses & limitations", "## Training and evaluation data", "## Training procedure", "### Training hyperparameters", "### Training results", "### Framework versions"]}, {"cogbuji/Mr-Grammatology-clinical-problems-Mistral-7B-0.5": ["## Use with mlx", "## Example of use of 1-shot description prompting", "## Question ##", "## Answer ##", "## Question ##"]}, {"elliotwork/swin-tiny-patch4-window7-224_brain_tumour": []}, {"NbAiLab/nb-gpt-j-6B-torgersen": []}, {"raphaelfontes/HealthNewsBRT": ["## Introduction", "### Pretrained Model (BERTimbau)", "## Classification report", "## Dataset", "## Data Splitting", "## Usage"]}, {"Harry-woolnough/mistrueue": ["## Model Details", "### Model Description", "### Model Sources [optional]", "## Uses", "### Direct Use", "### Downstream Use [optional]", "### Out-of-Scope Use", "## Bias, Risks, and Limitations", "### Recommendations", "## How to Get Started with the Model", "## Training Details", "### Training Data", "### Training Procedure ", "#### Preprocessing [optional]", "#### Training Hyperparameters", "#### Speeds, Sizes, Times [optional]", "## Evaluation", "### Testing Data, Factors & Metrics", "#### Testing Data", "#### Factors", "#### Metrics", "### Results", "#### Summary", "## Model Examination [optional]", "## Environmental Impact", "## Technical Specifications [optional]", "### Model Architecture and Objective", "### Compute Infrastructure", "#### Hardware", "#### Software", "## Citation [optional]", "## Glossary [optional]", "## More Information [optional]", "## Model Card Authors [optional]", "## Model Card Contact"]}, {"IT-community/HeartDiseaseClassification": ["## Overview", "## Dataset", "## Model Architecture", "## Cleaning Techniques", "## Usage", "## License", "## Contact"]}, {"clinicalnlplab/me-llama": ["## Model Overview", "## Pretraining and Data", "## Evaluation", "### Performance", "## Model Details", "## Usage"]}]