[{"TheBloke/med42-70B-GGUF": ["## Description", "### About GGUF", "## Repositories available", "## Prompt template: Med42", "## Licensing", "## Compatibility", "## Explanation of quantisation methods", "## Provided files", "### Q6_K and Q8_0 files are split and require joining", "### q6_K ", "### q8_0", "## How to download GGUF files", "### In `text-generation-webui`", "### On the command line, including multiple files at once", "## Example `llama.cpp` command", "## How to run in `text-generation-webui`", "## How to run from Python code", "### How to load this model in Python code, using ctransformers", "#### First install the package", "#### Simple ctransformers example code", "## How to use with LangChain", "## Discord", "## Thanks, and how to contribute", "## Model Details", "## Intended Use", "## Hardware and Software", "## Evaluation Results", "### Key performance metrics:", "## Limitations & Safe Use", "## Accessing Med42 and Reporting Issues"]}, {"TheBloke/med42-70B-AWQ": ["## Description", "### About AWQ", "## Repositories available", "## Prompt template: Med42", "## Licensing", "## Provided files, and AWQ parameters", "## How to easily download and use this model in [text-generation-webui](https://github.com/oobabooga/text-generation-webui)", "## Multi-user inference server: vLLM", "## Multi-user inference server: Hugging Face Text Generation Inference (TGI)", "## Inference from Python code using AutoAWQ", "### Install the AutoAWQ package", "### AutoAWQ example code", "## Compatibility", "## Discord", "## Thanks, and how to contribute", "## Model Details", "## Intended Use", "## Hardware and Software", "## Evaluation Results", "### Key performance metrics:", "## Limitations & Safe Use", "## Accessing Med42 and Reporting Issues"]}, {"m42-health/med42-70b": ["## Model Details", "## Intended Use", "## Hardware and Software", "## Evaluation Results", "### Key performance metrics:", "## Limitations & Safe Use", "## Accessing Med42 and Reporting Issues", "## Citation"]}, {"portugueseNLP/medialbertina_pt-pt_900m": ["## Data", "## How to use", "## Citation"]}, {"portugueseNLP/medialbertina_pt-pt_1.5b_NER": ["## Data", "## How to use", "## Citation"]}, {"portugueseNLP/medialbertina_pt-pt_900m_NER": ["## Data", "## How to use", "## Citation"]}, {"portugueseNLP/medialbertina_pt-pt_1.5b": ["## Data", "## How to use", "## Citation"]}, {"StanfordShahLab/clmbr-t-base": ["## Model Details", "### Model Description", "### Model Sources", "## Uses", "### Direct Use", "### Out-of-Scope Use", "## Bias, Risks, and Limitations", "## How to Get Started with the Model", "## Training Details", "### Training Data", "### Training Procedure", "#### Preprocessing", "#### Training Hyperparameters", "## Evaluation", "## Technical Specifications", "## Vocabulary", "## Citation", "## Model Card Authors", "## Model Card Contact"]}, {"Zamoranesis/mental_bert": ["## Model description", "## Intended uses & limitations", "## Training and evaluation data", "## Training procedure", "### Training hyperparameters", "### Training results", "### Framework versions"]}, {"ClinicalNLP/SDOHv7": ["## Validation Metrics", "## Usage"]}, {"Zamoranesis/clinical_transcripts_roberta": ["## Model description", "## Intended uses & limitations", "## Training and evaluation data", "## Training procedure", "### Training hyperparameters", "### Training results", "### Framework versions"]}, {"Zamoranesis/delirium_roberta": ["## Model description", "## Intended uses & limitations", "## Training and evaluation data", "## Training procedure", "### Training hyperparameters", "### Training results", "### Framework versions"]}, {"Zamoranesis/clinical_bert": ["## Model description", "## Intended uses & limitations", "## Training and evaluation data", "## Training procedure", "### Training hyperparameters", "### Training results", "### Framework versions"]}, {"TheBloke/med42-70B-GPTQ": ["## Description", "## Repositories available", "## Prompt template: Med42", "## Licensing", "## Known compatible clients / servers", "## Provided files, and GPTQ parameters", "## How to download, including from branches", "### In text-generation-webui", "### From the command line", "### With `git` (**not** recommended)", "## How to easily download and use this model in [text-generation-webui](https://github.com/oobabooga/text-generation-webui)", "## Serving this model from Text Generation Inference (TGI)", "## How to use this GPTQ model from Python code", "### Install the necessary packages", "### You can then use the following code", "## Compatibility", "## Discord", "## Thanks, and how to contribute", "## Model Details", "## Intended Use", "## Hardware and Software", "## Evaluation Results", "### Key performance metrics:", "## Limitations & Safe Use", "## Accessing Med42 and Reporting Issues"]}, {"Kabatubare/web-md-llama2-7b-3000": ["## Model Details", "### Base Model", "### Fine-tuned Model", "### Architecture and Training Parameters", "#### Architecture", "#### Training Parameters", "## Datasets", "### ", "### Fine-tuning Dataset", "## Usage"]}, {"Zamoranesis/clinical_transcripts_roberta_distilled": ["## clinical_transcripts_roberta_distilled", "## Model description", "## Intended uses & limitations", "## Training and evaluation data", "## Training procedure", "### Training hyperparameters", "### Training results", "### Framework versions"]}, {"ahmed-ai/galen": ["### Galen's view about future of medicine and AI:"]}, {"cja5553/BJH-perioperative-notes-bioGPT": ["## Dataset ", "## How to use model", "## Codes", "## Citation", "## Questions?"]}, {"StanfordShahLab/clmbr-t-base-random": ["## Model Details", "### Model Description", "### Model Sources", "## Uses", "## How to Get Started with the Model", "## Training Details", "## Evaluation", "## Technical Specifications", "### Compute Infrastructure", "#### Software", "## Citation", "## Model Card Authors", "## Model Card Contact"]}, {"mlninad/WellnessWhiz": ["## Model Description", "## Training procedure", "### Training hyperparameters", "### Framework versions", "### Prompt Template", "### Human: If you are a doctor, please answer the medical questions based on the patient's description.", "### Patient's Description: {symptoms}", "### Assistant: \"\""]}, {"Elysr/TrialMatchLLM": ["## ************************************************", "## \ud83c\udf00 TrialMatchLLM", "## Harnessing LLM for Eligibility Assessment in Clinical Research", "## **Try it:**", "## - **https://trialmatchllm.com/**", "## ************************************************", "## Example Usage"]}, {"cja5553/BJH-perioperative-notes-bioClinicalBERT": ["## Dataset", "## How to use model", "## Codes", "## Citation", "## Questions?"]}, {"StanfordShahLab/motor-t-base": ["## Model Details", "### Model Description", "### Model Sources", "## Uses", "### Direct Use", "### Out-of-Scope Use", "## Bias, Risks, and Limitations", "## How to Get Started with the Model", "## Training Details", "### Training Data", "### Training Procedure", "#### Preprocessing", "#### Training Hyperparameters", "## Evaluation", "## Technical Specifications", "## Citation", "## Model Card Authors", "## Model Card Contact"]}, {"drmasad/HAH-2024-v0.11": ["## Model Details", "### Model Description", "## Uses", "### Direct Use", "### Downstream Use [optional]", "### Out-of-Scope Use", "## Bias, Risks, and Limitations", "### Recommendations", "## How to Get Started with the Model"]}, {"fine-tuned/TRECCOVID-512-192-gpt-4o-2024-05-13-347397": ["## How to Use"]}]