[{"IIC/roberta-large-bne-livingner1": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/xlm-roberta-large-livingner1": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/mdeberta-v3-base-meddocan": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/bsc-bio-ehr-es-meddocan": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/roberta-large-bne-meddocan": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/mdeberta-v3-base-nubes": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/roberta-large-bne-nubes": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/xlm-roberta-large-nubes": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/BETO_Galen-nubes": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/mdeberta-v3-base-pharmaconer": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/roberta-large-bne-pharmaconer": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/bert-base-spanish-wwm-cased-socialdisner": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/mdeberta-v3-base-socialdisner": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/bsc-bio-ehr-es-socialdisner": ["## Parameters used", "## BibTeX entry and citation info"]}, {"camila-ud/DrBERT-CASM2": ["## Model description", "## Limitations and bias", "## Install medkit", "## Using the model", "## Training procedure", "## How to evaluate using medkit"]}, {"IDEA-CCNL/Yuyuan-Bart-139M": ["## \u7b80\u4ecb Brief Introduction", "## \u6a21\u578b\u5206\u7c7b Model Taxonomy", "## \u6a21\u578b\u4fe1\u606f Model Information", "## \u4f7f\u7528 Usage", "## \u5f15\u7528 Citation"]}, {"chizhikchi/Spanish_disease_finder": []}, {"IIC/bsc-bio-ehr-es-cantemist": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/XLM_R_Galen-cantemist": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/XLM_R_Galen-caresC": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/bert-base-spanish-wwm-cased-distemist": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/BETO_Galen-distemist": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/XLM_R_Galen-distemist": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/bert-base-spanish-wwm-cased-ehealth_kd": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/bsc-bio-ehr-es-ehealth_kd": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/BETO_Galen-ehealth_kd": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/XLM_R_Galen-ehealth_kd": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/bert-base-spanish-wwm-cased-livingner1": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/XLM_R_Galen-livingner1": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/BETO_Galen-meddocan": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/bert-base-spanish-wwm-cased-nubes": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/bsc-bio-ehr-es-nubes": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/XLM_R_Galen-nubes": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/bert-base-spanish-wwm-cased-pharmaconer": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/bsc-bio-ehr-es-livingner3": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/roberta-large-bne-socialdisner": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/BETO_Galen-socialdisner": ["## Parameters used", "## BibTeX entry and citation info"]}, {"BSC-NLP4BIA/biomedical-semantic-relation-classifier": ["## Table of contents", "## Model description", "## Intended uses and limitations", "## How to use", "## Training", "## Evaluation", "## Additional information", "### Author", "### Licensing information", "### Citation information", "### Disclaimer"]}, {"IIC/XLM_R_Galen-caresA": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/BETO_Galen-livingner1": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/XLM_R_Galen-meddocan": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/XLM_R_Galen-pharmaconer": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/XLM_R_Galen-livingner3": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/XLM_R_Galen-socialdisner": ["## Parameters used", "## BibTeX entry and citation info"]}, {"abazoge/DrBERT-4096": ["### Model pretraining", "### Model Usage", "### Citation"]}, {"BSC-NLP4BIA/biomedical-term-classifier": ["## Table of contents", "## Model description", "## Intended uses and limitations", "## How to use", "## Training", "## Evaluation", "## Additional information", "### Author", "### Licensing information", "### Citation information", "### Disclaimer"]}, {"whaleloops/longt5-tglobal-large-16384-pubmed-10k_steps": ["## Introduction", "## Results and Fine-tuning Details ", "## Usage"]}, {"bmi-labmedinfo/Igea-1B-v0.0.1": ["## How to use Igea with Hugging Face transformers", "## \ud83d\udea8\u26a0\ufe0f\ud83d\udea8 Bias, Risks, and Limitations \ud83d\udea8\u26a0\ufe0f\ud83d\udea8", "## Training and evaluation data", "## Training procedure", "### Training hyperparameters", "### Training results", "### Framework versions", "### Recommendations", "## Evaluation", "## Credits"]}, {"BSC-NLP4BIA/biomedical-semantic-relation-classifier-setfit": ["## Table of contents", "## Model description", "## Intended uses and limitations", "## How to use", "## Training", "## Evaluation", "## Additional information", "### Author", "### Licensing information", "### Citation information", "### Disclaimer"]}, {"Dr-BERT/DrBERT-4GB-CP-CamemBERT": ["## 3.1 Install dependencies", "## 3.2 Download NACHOS Dataset text file", "## 3.3 Build your own tokenizer from scratch based on NACHOS", "## 3.4 Preprocessing and tokenization of the dataset", "## 3.5 Model training", "### 3.5.1 Pre-training from scratch", "### 3.5.2 continue pre-training"]}]