[{"bvanaken/clinical-assertion-negation-bert": ["## Model description", "#### How to use the model", "### Cite"]}, {"yikuan8/Clinical-Longformer": ["### Pre-training", "### Usage", "### Citing", "### Questions"]}, {"aaditya/Llama3-OpenBioLLM-70B": ["### Use with transformers", "## **Training procedure**", "### **Training hyperparameters**", "### **Peft hyperparameters**", "### **Training results**", "### **Framework versions**", "## Detailed Medical Subjectwise accuracy"]}, {"ruslanmv/Medical-Llama3-8B": []}, {"almanach/camembert-bio-base": ["## Absract", "## Training Details", "### Training Data", "### Training Procedure ", "## Evaluation", "### Fine-tuning", "### Scoring", "### Results ", "## Environmental Impact estimation", "## Citation information"]}, {"PlanTL-GOB-ES/bsc-bio-ehr-es": ["## Table of contents", "## Model description", "## Intended uses and limitations", "## How to use", "## Limitations and bias", "## Training", "### Tokenization and model pretraining", "### Training corpora and preprocessing", "## Evaluation ", "## Additional information", "### Author", "### Contact information", "### Copyright", "### Licensing information", "### Funding", "### Citing information", "### Disclaimer"]}, {"bvanaken/CORe-clinical-outcome-biobert-v1": ["## Model description", "#### How to use CORe", "### Pre-Training Data", "### More Information", "### Cite"]}, {"mradermacher/OpenBioLLM-Llama3-70B-i1-GGUF": ["## About", "## Usage", "## Provided Quants", "## FAQ / Model Request", "## Thanks"]}, {"yikuan8/Clinical-BigBird": ["### Pre-training", "### Usage", "### Citing", "### Questions"]}, {"DATEXIS/CORe-clinical-diagnosis-prediction": ["## Model description", "#### Model Predictions", "#### How to use CORe Diagnosis Prediction", "### More Information", "### Cite"]}, {"mradermacher/OpenBioLLM-Llama3-70B-GGUF": ["## About", "## Usage", "## Provided Quants", "## FAQ / Model Request", "## Thanks"]}, {"LiteLLMs/Llama3-OpenBioLLM-70B-GGUF": ["## Description", "### About GGUF", "## Explanation of quantisation methods", "## How to download GGUF files", "### In `text-generation-webui`", "### On the command line, including multiple files at once", "## Example `llama.cpp` command", "## How to run in `text-generation-webui`", "## How to run from Python code", "### How to load this model in Python code, using llama-cpp-python", "#### First install the package", "#### Simple llama-cpp-python example code", "## How to use with LangChain", "## Description", "### About GGUF", "## Explanation of quantisation methods", "## How to download GGUF files", "### In `text-generation-webui`", "### On the command line, including multiple files at once", "## Example `llama.cpp` command", "## How to run in `text-generation-webui`", "## How to run from Python code", "### How to load this model in Python code, using llama-cpp-python", "#### First install the package", "#### Simple llama-cpp-python example code", "## How to use with LangChain", "### Use with transformers", "## **Training procedure**", "### **Training hyperparameters**", "### **Peft hyperparameters**", "### **Training results**", "### **Framework versions**", "## Detailed Medical Subjectwise accuracy"]}, {"PlanTL-GOB-ES/bsc-bio-ehr-es-pharmaconer": ["## Table of contents", "## Model description", "## Intended uses and limitations", "## How to use", "## Limitations and bias", "## Training", "## Evaluation ", "## Additional information", "### Author", "### Contact information", "### Copyright", "### Licensing information", "### Funding", "## Citing information", "### Disclaimer"]}, {"PlanTL-GOB-ES/roberta-base-biomedical-clinical-es": ["## Table of contents", "## Model description", "## Intended uses and limitations", "## How to use", "## Limitations and bias", "## Training", "## Evaluation ", "## Additional information", "### Author", "### Contact information", "### Copyright", "### Licensing information", "### Funding", "### Citation information", "### Disclaimer"]}, {"PlanTL-GOB-ES/bsc-bio-es": ["## Table of contents", "## Model description", "## Intended uses and limitations", "## How to use", "## Limitations and bias", "## Training", "### Tokenization and model pretraining", "### Training corpora and preprocessing", "## Evaluation ", "## Additional information", "### Author", "### Contact information", "### Copyright", "### Licensing information", "### Funding", "### Citation information", "### Disclaimer"]}, {"abazoge/DrLongformer": ["### Model pretraining", "### Model Usage", "### Citation"]}, {"portugueseNLP/medialbertina_pt-pt_900m": ["## Data", "## How to use", "## Citation"]}, {"DATEXIS/CORe-clinical-mortality-prediction": ["## Model description", "#### How to use CORe Mortality Risk Prediction", "### More Information", "### Cite"]}, {"PlanTL-GOB-ES/longformer-base-4096-biomedical-clinical-es": ["## Table of contents", "## Model description", "## Intended uses and limitations", "## How to use", "## Limitations and bias", "## Training", "## Evaluation", "## Additional information", "### Author", "### Contact information", "### Copyright", "### Licensing information", "### Funding", "### Disclaimer"]}, {"whaleloops/keptlongformer": ["### Pre-training", "### Usage"]}, {"Writer/Palmyra-Med-70B": ["## Model Details", "#### Specialized for Biomedical Applications", "### Model Description", "## Intended Use", "### Use with transformers", "## Evaluation Results", "### Performance on Biomedical Benchmarks", "### Medical Use Cases", "### Bias, Risks, and Limitations", "### Citation and Related Information"]}, {"portugueseNLP/medialbertina_pt-pt_1.5b_NER": ["## Data", "## How to use", "## Citation"]}, {"whaleloops/KEPTlongformer-PMM3": ["### Pre-training", "### Usage"]}, {"nlpie/Llama2-MedTuned-7b": []}, {"nlpie/Llama2-MedTuned-13b": []}, {"portugueseNLP/medialbertina_pt-pt_900m_NER": ["## Data", "## How to use", "## Citation"]}, {"almanach/camembert-bio-gliner-v0.1": ["## Important", "## Installation", "## Usage", "## Links"]}, {"portugueseNLP/medialbertina_pt-pt_1.5b": ["## Data", "## How to use", "## Citation"]}, {"PlanTL-GOB-ES/bsc-bio-ehr-es-cantemist": ["## Table of contents", "## Model description", "## Intended uses and limitations", "## How to use", "## Limitations and bias", "## Training", "## Evaluation ", "## Additional information", "### Author", "### Contact information", "### Copyright", "### Licensing information", "### Funding", "### Citing information", "### Disclaimer"]}, {"Mbilal755/Radiology_Bart": ["## Model Highlights", "### Parent Model ", "## Model Architecture", "## Data", "## Training", "## Performance", "## Usage", "## Limitations", "## Check Demo", "## Model Card Contact"]}, {"BSC-LT/roberta-base-biomedical-clinical-es": ["## Tokenization and model pretraining", "## Training corpora and preprocessing", "## Evaluation and results", "## Intended uses & limitations", "## Cite", "## How to use"]}, {"Emmytheo/DiagBERT": ["## Model description", "#### Model Predictions", "#### How to use CORe Diagnosis Prediction", "### More Information", "### Cite"]}, {"mrm8488/biomedtra-small-finenuned-clinical-ner": []}, {"IIC/xlm-roberta-large-distemist": ["## Parameters used", "## BibTeX entry and citation info"]}, {"janduplessis886/clinical_text_classification": ["## Usage ", "## Topic overview", "## Training hyperparameters", "## Framework versions"]}, {"IIC/xlm-roberta-large-livingner3": ["## Parameters used", "## BibTeX entry and citation info"]}, {"DATEXIS/clinical-assertion-negation-bert": ["## Model description", "#### How to use the model", "### Cite"]}, {"chizhikchi/sci-five-radsum23": []}, {"IIC/xlm-roberta-large-caresA": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/xlm-roberta-large-caresC": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/xlm-roberta-large-ctebmsp": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/bert-base-spanish-wwm-cased-cantemist": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/roberta-large-bne-cantemist": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/mdeberta-v3-base-caresA": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/roberta-large-bne-caresA": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/mdeberta-v3-base-caresC": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/roberta-large-bne-caresC": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/xlm-roberta-large-ehealth_kd": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/xlm-roberta-large-meddocan": ["## Parameters used", "## BibTeX entry and citation info"]}, {"IIC/mdeberta-v3-base-livingner3": ["## Parameters used", "## BibTeX entry and citation info"]}]